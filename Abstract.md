## Evaluating Caches with multiple caching strategies ##

Current data cache organizations fail to deliver high performance in scalar processors for many different applications. On-disk sequentiality of requested blocks, or their spatial locality, is critical to real disk performance where the throughput of access to sequentially-placed disk blocks can be an order of magnitude higher than that of access to randomly-placed blocks. Unfortunately, spatial locality of cached blocks is largely ignored, and only temporal locality is considered in current system buffer cache managements.

In the current practice, there are several major efforts in parallel to break the disk bottleneck. One effort is to reduce disk accesses through memory caching. Another effort to break the disk bottleneck is reducing disk arm seeks through I/O request scheduling. I/O scheduler reorders pending requests in a block deviceâ€™s request queue into a dispatching order that results in minimal seeks and thereafter maximal global disk throughput. The third effort is prefetching. A prefetching manager predicts future request patterns associated with a file opened by a process. If a sequential access pattern is detected, then the prefetching manager issues requests for the blocks following the current on-demand block on behalf of the process.

Concerned with the lack of ability to exploit spatial locality in buffer cache management, (because in the worst case, a stream filled with random accesses makes I/O scheduling and prefetching largely ineffective because no spatial locality is left for them to exploit) , our solution to the deteriorating disk bottleneck is a new buffer cache management scheme that exploits both temporal and spatial localities which we call the DUal LOcality scheme (DULO). DULO introduces dual locality into the caching component in an operating system by tracking and utilizing disk placements of in-memory pages in its buffer cache management.
